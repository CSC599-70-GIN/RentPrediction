Jupyter Notebook: https://github.com/CSC599-70-GIN/RentPrediction/blob/master/main.ipynb

1a. We used two external datasets linked below: NYPD complaints and 311 service request data. We chose these datasets because we believe there is a correlation between the number of complaints and service requests and the rent prices. Typically the greater the number or severity of crimes in a neighborhood, the less people are willing to pay to live there.

311 Service Requests: https://nycopendata.socrata.com/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9

NYPD Complaints: https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i

1b. We don’t believe this raises any ethical considerations as both datasets are publicly available and do not identify any specific people. Both datasets were also provided by government agencies. One ethical consideration that could be brought up is that if the complaint or service request data is used to generalize the characteristics of a neighborhood, but that is outside the scope of this project. 

2a. The features ‘year_built’, ‘addr_unit’, ‘min_to_subway’ , ‘unit’, ‘floornumber’, and ‘line’ had many missing values. We removed these columns because we decided that any impact they could have would be insignificant. Another feature called ‘bin’ was missing only one row in the train set so we just removed that row, two rows were also missing for ‘bin’ in submit2_df which we handled by filling them in with values we inferred they would based on the relationship between ‘bin’ and ‘bbl’. 

2b. They weren’t too difficult to deal with since we just mostly chose to remove the rows that were missing or just removed the columns if there were too many missing and very rarely did we choose to actually fill in the missing data with something.

2c. Some of the columns have string as their type which can’t be used unless we convert them to integer.

2d. There is a scatter plot in our notebook which graphs the relation between size sqft and the rent and you can see it as size sqft goes up so does rent. While there are problems with the distribution of data in the scatter plot you can still see the trend which shows there is a positive relationship between the two.

3a. The five features that played the biggest role in our model were: ‘size_sqft’, ‘floor_count’, ‘bedrooms’, ‘bbl’, and ‘bin’. We didn’t create these features since they were already included in the StreetEasy dataset given to us. We know these features play a key role because we ran feature importances on our model which tells us which feature contributed the most to the model’s predictive power and these features are the top five contributors to our model.

3b. We are using a gradient boosting model on as many features as we can and then hypertuning the parameters to optimize our model’s performance. We use use RandomSearchCV to hypertune our parameters so overfitting should not be a big problem for us since it adjusts the parameters based on the cross validation score. This works well because we let the computer handle optimizing the model.

3c. The model we chose was gradient boosting and it works well because it trains an algorithm initially then improves that algorithm by prioritizing data set where the algorithm was wrong. We chose this model because gradient boosting gave us a better MSE and a better variance compared to random forest when we tuned the hyper parameters for both of them. 

4a. I think model will perform much better compared to before because out average MSE score based on five fold cross validation is lower and out variation is also lower now. So I expect the model to perform somewhere between 0.6 million to 1.3 million MSE.

4b. We believe our model is useful because our R2 score is approximately 0.9 and the difference between train and test scores is very small indicating lower variance.

4c. Our model would work particularly well on StreetEasy rental data for NYC, but if we try to use this outside of this constraint we will run into problems since we are only looking at rental source from one company and only for NYC. Our external datasets also would only work for NYC.

4d. We created a bar graph of different models R2 score for train and test dataset on our model. This compares the predictive power of our model by comparing it to our previous models. Our current model is the optimized gradient boosting model and it has the highest train R2 score and the smallest difference between train and test R2 score proving our model’s predictive power.

5a. We can use this model to decide at what price we should rent an apartment on StreetEasy. Since the model uses data from StreetEasy it’s fair to assume that the price generated by our model will help us rent our properties at a fair price.

5b. Cost of utilities for the property would be a nice feature to have. I am sure there should be some variation in the price of water, gas, and electricity which is a consideration I am sure property owners take those into consideration when setting a price for the rent.

5c. More data would be better because ensemble models like random forest and gradient boosting tend to overfit so more data would help us get closer to the true prediction. While there is a certain point where more data gives diminishing returns we believe that we haven’t reached that point yet. 

